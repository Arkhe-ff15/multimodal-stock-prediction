# ==============================================================================
# TEST CONFIGURATION - Fast Testing & Development
# Inherits from unified config but with smaller scope for speed
# ==============================================================================

# Data Configuration - REDUCED SCOPE FOR TESTING
data:
  stocks: ['AAPL', 'MSFT']      # Only 2 stocks for faster testing
  start_date: '2023-01-01'      # Shorter time period (1 year)
  end_date: '2024-01-31'
  cache_enabled: true
  use_parallel: false           # Sequential for easier debugging
  
  # Same sentiment sources but will generate less data
  sentiment_sources:
    sec_edgar:
      enabled: true
      weight: 0.25
      reliability: 1.0
    federal_reserve:
      enabled: true
      weight: 0.20
      reliability: 1.0
    investor_relations:
      enabled: true
      weight: 0.25
      reliability: 0.95
    bloomberg_twitter:
      enabled: true
      weight: 0.20
      reliability: 0.85
    yahoo_finance:
      enabled: true
      weight: 0.10
      reliability: 0.75
  
  # Same technical indicators
  technical_indicators:
    basic: ['Open', 'High', 'Low', 'Close', 'Volume']
    moving_averages: [5, 10, 20, 50]     # Fewer periods for speed
    rsi_periods: [14]                     # Just one RSI period
    macd_params: 
      fast: 12
      slow: 26
      signal: 9
    bollinger_periods: [20]
    vwap_periods: [20]                    # Just one VWAP period
    lag_periods: [1, 2, 3, 5]            # Fewer lag periods
  
  # Company mapping - same as unified config
  company_mapping:
    AAPL:
      name: 'Apple Inc'
      sector: 'Technology'
      keywords: ['apple', 'iphone', 'ipad', 'mac', 'ios', 'tim cook', 'cupertino']
      cik: '0000320193'
    MSFT:
      name: 'Microsoft Corporation'
      sector: 'Technology'
      keywords: ['microsoft', 'windows', 'office', 'azure', 'xbox', 'satya nadella']
      cik: '0000789019'

# Sentiment Analysis Configuration - SMALLER BATCHES FOR TESTING
sentiment:
  model_name: "ProsusAI/finbert"
  batch_size: 8                # Smaller batch size for testing
  max_length: 512
  
  # Same quality thresholds as unified config
  confidence_threshold: 0.7
  relevance_threshold: 0.85
  quality_threshold: 0.7
  
  min_text_length: 10
  max_text_length: 1000        # Shorter max length for speed
  
  cache_results: true
  device: "auto"
  
  quality_filters:
    min_length: true
    language_filter: true
    relevance_check: true
    confidence_filter: true
    duplicate_filter: true

# Temporal Decay Configuration - SAME AS UNIFIED
temporal_decay:
  lambda_5: 0.3
  lambda_30: 0.1
  lambda_90: 0.05
  
  lookback_days:
    5: 10
    30: 30
    90: 60
  
  min_sentiment_count: 3
  min_confidence: 0.7

# Model Configuration - SMALLER FOR FASTER TRAINING
model:
  hidden_size: 32              # Smaller hidden size
  attention_head_size: 2       # Fewer attention heads
  dropout: 0.3
  num_lstm_layers: 1           # Fewer LSTM layers
  
  learning_rate: 0.001
  batch_size: 16               # Smaller batch size
  max_epochs: 10               # Fewer epochs for testing
  early_stopping_patience: 5
  gradient_clip_val: 1.0
  weight_decay: 1e-4
  
  max_encoder_length: 20       # Shorter sequences
  max_prediction_length: 1
  training_cutoff_days: 180    # Shorter training period
  
  cv_folds: 3                  # Fewer CV folds
  cv_method: 'time_series'
  
  variants:
    - 'TFT-Temporal-Decay'     # Focus on main model for testing
    - 'TFT-Static-Sentiment'   # One comparison model

# Multi-Horizon Prediction Configuration - SAME AS UNIFIED
horizons: [5, 30, 90]

# Target variables - SAME AS UNIFIED
targets:
  prediction_types:
    - 'returns'
    - 'direction'
    - 'volatility'
  
  decision_thresholds:
    buy_threshold: 0.05
    sell_threshold: -0.03

# Evaluation Configuration - SIMPLIFIED
evaluation:
  significance_level: 0.05
  min_observations: 20         # Lower minimum for testing
  
  metrics: ['RMSE', 'MAE', 'R2', 'directional_accuracy']  # Fewer metrics
  
  statistical_tests: ['wilcoxon']  # Just one test for speed
  
  explainability:
    feature_importance: true
    attention_analysis: false    # Skip for testing
    sentiment_attribution: true
    temporal_contribution: true
    investment_reasoning: false  # Skip for testing

# Experiment Configuration
experiment:
  name: "Test-Multi-Horizon-Sentiment-TFT"
  version: "test-v1.0"
  description: "Fast testing configuration"
  save_results: true
  save_intermediate_results: true
  create_report: false         # Skip report generation for speed

# File Paths - SAME AS UNIFIED
paths:
  raw_data: 'data/raw'
  processed_data: 'data/processed'
  cache_dir: 'data/cache'
  results_dir: 'results'
  models_dir: 'results/models'
  plots_dir: 'results/plots'
  reports_dir: 'results/reports'
  
  combined_dataset: 'test_combined_dataset.parquet'
  sentiment_features: 'test_sentiment_features.parquet'
  temporal_decay_features: 'test_temporal_decay_features.parquet'

# Data Quality Requirements - RELAXED FOR TESTING
quality_requirements:
  min_trading_days: 100        # Lower requirement for testing
  min_news_articles: 20        # Lower requirement for testing
  max_missing_data_pct: 10     # More tolerant of missing data
  min_sentiment_coverage: 0.6  # Lower coverage requirement
  
  required_technical_indicators: ['EMA_20', 'RSI_14', 'MACD']  # Fewer required
  required_sentiment_sources: ['sec_edgar', 'investor_relations']  # Fewer required

# Performance and Hardware - CONSERVATIVE FOR TESTING
performance:
  parallel_processing: false   # Sequential for debugging
  chunk_size: 500             # Smaller chunks
  memory_limit_mb: 2048       # Lower memory limit
  num_workers: 1              # Single worker for debugging
  use_gpu: false              # CPU only for testing consistency
  mixed_precision: false

# Reproducibility - SAME AS UNIFIED
random_seed: 42

# Logging Configuration - MORE VERBOSE FOR TESTING
logging:
  level: "DEBUG"              # More verbose logging
  save_logs: true
  log_file: "test_experiment.log"
  console_output: true

# Error Handling - MORE PERMISSIVE FOR TESTING
error_handling:
  continue_on_symbol_failure: true
  max_symbol_failures: 2     # Allow more failures in testing
  retry_failed_symbols: false # Don't retry in testing
  graceful_degradation: true

# Validation and Testing - SAME AS UNIFIED
validation:
  run_data_quality_checks: true
  validate_technical_indicators: true
  validate_sentiment_sources: true
  validate_date_coverage: true
  validate_feature_completeness: true

# ==============================================================================
# TEST CONFIGURATION NOTES:
# ==============================================================================
# 
# OPTIMIZATIONS FOR TESTING:
# - Only 2 stocks (AAPL, MSFT) instead of 5
# - 1 year date range instead of 5+ years
# - Smaller model architecture (32 hidden units vs 64)
# - Fewer epochs (10 vs 50)
# - Smaller batch sizes for faster iteration
# - Sequential processing for easier debugging
# - More verbose logging for development
# 
# USAGE:
# python run_experiment.py --config configs/test_config.yaml --steps 1 2 3
# 
# EXPECTED RUNTIME:
# - Step 1: 2-5 minutes
# - Step 2: 3-8 minutes  
# - Step 3: 1-2 minutes
# Total: ~10-15 minutes vs 60+ minutes for full config
# ==============================================================================