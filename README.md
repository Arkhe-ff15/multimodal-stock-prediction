# ðŸ“ˆ Temporal Decay Sentiment-Enhanced Financial Forecasting with FinBERT-TFT Architecture

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **A robust research framework implementing temporal decay sentiment weighting in Temporal Fusion Transformer (TFT) architectures for enhanced financial forecasting through FinBERT-processed news sentiment analysis.**

## ðŸŽ¯ Abstract

This repository presents a novel approach to financial time series forecasting by integrating FinBERT-derived sentiment features with exponential temporal decay weighting into Temporal Fusion Transformer (TFT) models. The framework processes large-scale FNSPID financial news datasets through automated sentiment analysis pipelines and applies mathematically-grounded temporal decay mechanisms to capture sentiment persistence effects across multiple forecasting horizons.

**Primary Research Contribution:**
Implementation and validation of exponential temporal decay sentiment weighting in transformer-based financial forecasting, demonstrating significant performance improvements over baseline technical indicator models through rigorous comparative analysis.

**Key Technical Innovations:**
- Exponential temporal decay methodology for multi-horizon sentiment feature engineering
- Automated production-grade pipeline for processing 22GB+ FNSPID datasets
- FinBERT-TFT integration architecture with robust error handling and validation
- Comprehensive benchmark framework comparing baseline vs. sentiment-enhanced models

## ðŸ”¬ Research Motivation

Financial markets exhibit complex temporal relationships between news sentiment and subsequent price movements that traditional technical analysis approaches may inadequately capture. While sentiment analysis has demonstrated promise in financial forecasting applications, existing methodologies typically treat sentiment as instantaneous signals without accounting for their temporal persistence, decay patterns, and varying influence across different prediction horizons.

This research systematically addresses three fundamental questions:

1. **How does financial news sentiment decay exponentially over time** in its predictive influence on stock price movements across multiple forecasting horizons?
2. **Can exponentially-weighted temporal sentiment features significantly improve TFT model performance** beyond conventional technical indicator baselines?
3. **What optimal decay parameters (Î»_h) maximize forecasting accuracy** for different prediction horizons (5-day, 30-day, 90-day)?

## ðŸ§® Mathematical Framework

### Exponential Temporal Decay Sentiment Weighting

Our methodology implements a mathematically rigorous exponential decay mechanism for sentiment feature engineering:

```
sentiment_weighted = Î£(sentiment_i * exp(-Î»_h * age_i)) / Î£(exp(-Î»_h * age_i))
```

**Where:**
- `sentiment_weighted`: Final temporally-decayed sentiment score
- `sentiment_i`: Original FinBERT sentiment score at time i
- `Î»_h`: Horizon-specific decay parameter (learned/optimized)
- `age_i`: Time distance from current prediction point (in days)
- `h`: Prediction horizon (5d, 30d, 90d)

**Mathematical Properties:**
- **Normalization**: Denominator ensures weighted average properties
- **Exponential Decay**: Recent sentiment receives exponentially higher weight
- **Horizon Adaptation**: Different Î»_h values for different prediction periods
- **Bounded Output**: Maintains sentiment score range [-1, 1]

**Implemented Decay Parameters:**
- `Î»_5d`: 0.1 (fast decay: 50% weight after ~7 days)
- `Î»_30d`: 0.05 (moderate decay: 50% weight after ~14 days)  
- `Î»_90d`: 0.02 (slow decay: 50% weight after ~35 days)

### Model Architecture Comparison

The framework implements three distinct model configurations for comparative analysis:

1. **LSTM Baseline**: Traditional LSTM with technical indicators exclusively
2. **TFT Baseline**: Temporal Fusion Transformer with technical features only
3. **TFT Enhanced (Primary)**: TFT with technical features + exponential decay sentiment

**Technical Feature Engineering:**
- **Price-Volume Indicators**: EMA(5,10,20), RSI(14), MACD, Bollinger Bands, ATR, VWAP
- **Temporal Encoding**: Time indices, seasonal patterns, trading day adjustments
- **Sentiment Features**: Multi-horizon exponential decay (5d, 30d, 90d) with FinBERT confidence weighting

## ðŸ—ï¸ Simplified Pipeline Architecture

The framework implements a clean, production-ready pipeline with independent modules:

**Pipeline Flow:**
```
config.yaml (Simple Configuration)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            STREAMLINED PIPELINE EXECUTION          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
Stage 1: data.py â†’ combined_dataset.csv (Core Dataset)
        â†“
Stage 2: fnspid_processor.py â†’ fnspid_daily_sentiment.csv
        â†“
Stage 3: temporal_decay.py â†’ temporal_decay_enhanced_dataset.csv
        â†“
Stage 4: sentiment.py â†’ final_dataset.csv (Enhanced)
        â†“
Stage 5: models.py â†’ trained_models/ (LSTM + TFT variants)
        â†“
Stage 6: evaluation.py â†’ comparative_results/
```

**Key Architectural Principles:**
- **Independent Modules**: Each stage can run standalone for testing
- **Simple Configuration**: YAML-based config without complex classes
- **Clean Data Flow**: Clear input/output files between stages
- **Robust Error Handling**: Graceful failure and recovery mechanisms
- **Production Ready**: Memory-efficient processing of large datasets

## ðŸ“ Repository Structure

```
sentiment_tft/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ config.yaml                        # Simple YAML configuration
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ verify_setup.py                    # Health check script
â”‚
â”œâ”€â”€ src/                               # Core pipeline modules
â”‚   â”œâ”€â”€ config_reader.py              # Simple config loading
â”‚   â”œâ”€â”€ data.py                       # Market data collection (production ready)
â”‚   â”œâ”€â”€ clean.py                      # Data cleaning utilities (production ready)
â”‚   â”œâ”€â”€ fnspid_processor.py           # FNSPID news sentiment analysis
â”‚   â”œâ”€â”€ temporal_decay.py             # Exponential decay feature engineering
â”‚   â”œâ”€â”€ sentiment.py                  # Sentiment feature integration
â”‚   â”œâ”€â”€ models.py                     # Model training (LSTM + TFT variants)
â”‚   â”œâ”€â”€ evaluation.py                 # Model comparison and evaluation
â”‚   â””â”€â”€ pipeline_orchestrator.py      # Automated pipeline execution
â”‚
â”œâ”€â”€ data/                              # Data storage (excluded from git)
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ nasdaq_exteral_data.csv   # 22GB FNSPID dataset (note: typo in filename)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ combined_dataset.csv      # Core technical dataset
â”‚       â”œâ”€â”€ fnspid_daily_sentiment.csv
â”‚       â”œâ”€â”€ temporal_decay_enhanced_dataset.csv
â”‚       â””â”€â”€ final_dataset.csv         # Enhanced dataset ready for training
â”‚
â”œâ”€â”€ models/                            # Model artifacts
â”‚   â”œâ”€â”€ lstm_baseline.pth
â”‚   â”œâ”€â”€ tft_baseline.pth
â”‚   â””â”€â”€ tft_enhanced.pth
â”‚
â””â”€â”€ results/                           # Evaluation outputs
    â”œâ”€â”€ evaluation_report_*.json
    â”œâ”€â”€ model_comparison_*.png
    â””â”€â”€ training_results.json
```

## ðŸš€ Installation & Setup

### System Requirements

**Hardware Specifications:**
- Python 3.8+ environment
- CUDA-compatible GPU (recommended for FinBERT processing)
- 16GB+ RAM (required for FNSPID dataset processing)
- 50GB+ available storage (raw data + processed artifacts + model checkpoints)

**Critical Dependencies:**
```bash
# Core ML/DL frameworks
torch>=2.0.0
pytorch-lightning>=2.0.0
pytorch-forecasting>=1.0.0

# FinBERT sentiment analysis
transformers>=4.30.0

# Financial data processing
pandas>=1.5.0
numpy>=1.24.0
ta>=0.10.2
yfinance>=0.2.18

# Research & visualization
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
pyyaml>=6.0
```

### Quick Setup

```bash
# 1. Clone repository
git clone https://github.com/your-username/sentiment_tft.git
cd sentiment_tft

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Verify setup
python verify_setup.py

# 5. Test individual modules
python src/fnspid_processor.py
```

## ðŸ“Š Data Requirements

### FNSPID Dataset Setup

**Primary Dataset:**
- **Source**: [FNSPID - Financial News and Stock Price Integration Dataset](https://www.kaggle.com/datasets/miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests)
- **Size**: ~22GB uncompressed CSV
- **Records**: 15M+ financial news articles with metadata
- **Required Location**: `data/raw/nasdaq_exteral_data.csv` *(note: filename has intentional typo)*
- **Expected Columns**: `Date`, `Article_title`, `Stock_symbol`

**Stock Price Data:**
- **Source**: Automated yfinance API integration via `data.py`
- **Default Symbols**: AAPL, MSFT, GOOGL, AMZN, NVDA, TSLA, META, NFLX
- **Output**: `data/processed/combined_dataset.csv` (production ready)

### Data Validation

```python
# Quick data check
from src.config_reader import load_config, get_data_paths

config = load_config()
paths = get_data_paths(config)

# Check required files
print(f"FNSPID data: {paths['raw_fnspid'].exists()}")
print(f"Core dataset: {paths['core_dataset'].exists()}")
```

## ðŸ”§ Usage & Execution

### Individual Module Testing

```bash
# Test each stage independently
python src/fnspid_processor.py      # Process FNSPID â†’ daily sentiment
python src/temporal_decay.py        # Apply exponential decay
python src/sentiment.py             # Integrate sentiment features
python src/models.py                # Train all model variants
python src/evaluation.py            # Compare model performance
```

### Automated Pipeline Execution

```bash
# Run complete pipeline
python src/pipeline_orchestrator.py

# Run specific stages
python src/pipeline_orchestrator.py --stages fnspid temporal_decay sentiment

# Run data processing only
python src/pipeline_orchestrator.py --data-only
```

### Configuration

Edit `config.yaml` to customize:

```yaml
data:
  core:
    symbols: ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA']
    start_date: '2020-01-01'
    end_date: '2024-01-31'
    target_horizons: [5, 30, 90]
  
  fnspid:
    production:
      sample_ratio: 0.15        # 15% of FNSPID data
      chunk_size: 75000

model:
  tft:
    max_encoder_length: 60
    max_prediction_length: 30
    batch_size: 64
    max_epochs: 100
```

## ðŸ“ˆ Model Training & Results

### Temporal Decay Feature Engineering

The core innovation lies in our exponential decay implementation:

```python
# Key algorithm implementation in temporal_decay.py
def calculate_exponential_decay(sentiment_history, current_date, lambda_param):
    ages = (current_date - sentiment_history['date']).dt.days
    weights = np.exp(-lambda_param * ages)
    
    weighted_sentiment = (sentiment_history['sentiment_compound'] * weights).sum() / weights.sum()
    return weighted_sentiment
```

### Model Comparison Framework

Three model variants for rigorous comparison:

1. **LSTM Baseline**: Traditional architecture with technical indicators
2. **TFT Baseline**: Modern transformer with technical features only
3. **TFT Enhanced**: TFT + exponential decay sentiment features

### Expected Performance Metrics

Based on initial validation:
- **5-15% MAE reduction** over technical baselines during high-sentiment periods
- **Enhanced directional accuracy** around news events
- **Statistical significance** (p < 0.05) in forecast improvement tests

## ðŸ”¬ Research Methodology

### Experimental Design

**Controlled Comparison:**
- Identical technical features across all models
- Temporal data splitting (no look-ahead bias)
- Statistical significance testing (Diebold-Mariano)
- Multiple forecasting horizons (5d, 30d, 90d)

**Validation Framework:**
- Walk-forward cross-validation
- Out-of-sample testing
- Robustness across market regimes
- Cross-symbol generalization

### Evaluation Metrics

```python
evaluation_metrics = {
    'accuracy': ['MAE', 'RMSE', 'MAPE'],
    'direction': ['Directional Accuracy', 'Hit Rate'],
    'statistical': ['Diebold-Mariano p-value'],
    'economic': ['Sharpe Ratio', 'Max Drawdown']
}
```

## ðŸš¨ Quick Start Guide

### Prerequisites Check
```bash
python verify_setup.py
```

### Minimum Working Example
```bash
# 1. Ensure data exists
ls data/raw/nasdaq_exteral_data.csv
ls data/processed/combined_dataset.csv

# 2. Run FNSPID processing
python src/fnspid_processor.py

# 3. Apply temporal decay
python src/temporal_decay.py

# 4. Integrate features
python src/sentiment.py

# 5. Train models
python src/models.py

# 6. Compare results
python src/evaluation.py
```

## ðŸ“Š Expected Outputs

### Data Pipeline Outputs
- `fnspid_daily_sentiment.csv`: FinBERT-processed daily sentiment scores
- `temporal_decay_enhanced_dataset.csv`: Multi-horizon decay features
- `final_dataset.csv`: Complete dataset ready for model training

### Model Training Outputs
- `lstm_baseline.pth`: Traditional LSTM baseline
- `tft_baseline.pth`: TFT with technical features only
- `tft_enhanced.pth`: TFT with sentiment enhancement

### Evaluation Outputs
- `evaluation_report_*.json`: Comprehensive performance comparison
- `model_comparison_*.png`: Performance visualization
- Statistical significance tests and improvement metrics

## ðŸ¤ Research Collaboration

This framework is designed for academic research collaboration:

**Contribution Areas:**
- Advanced temporal decay formulations
- Alternative sentiment sources integration
- Ensemble methodology development
- Domain-specific performance metrics

**Research Standards:**
```bash
# Comprehensive testing
python verify_setup.py
python -m pytest tests/ --cov=src/

# Reproducible results
python src/pipeline_orchestrator.py --seed=42
```

## ðŸ“š Citation

If this framework contributes to your research, please cite:

```bibtex
@software{temporal_decay_sentiment_tft_2024,
  title={Temporal Decay Sentiment-Enhanced Financial Forecasting with FinBERT-TFT Architecture},
  author={[Author Name]},
  year={2024},
  institution={ESI SBA},
  url={https://github.com/your-username/sentiment_tft},
  note={Implementation of exponential temporal decay sentiment weighting in transformer-based financial forecasting}
}
```

## ðŸ™ Acknowledgments

**Core Research Dependencies:**
- **FinBERT**: Araci, D. (2019). "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models"
- **Temporal Fusion Transformer**: Lim, B. et al. (2021). "Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting"
- **FNSPID Dataset**: Large-scale financial news dataset for academic research
- **PyTorch Forecasting**: Production-grade TFT implementation framework

---

**Research Contact:**
- **Primary Researcher**: mni.diafi@esi-sba.dz
- **Institution**: ESI SBA  
- **Research Group**: FF15

**Disclaimer**: This software is developed for academic research purposes. Not intended for commercial trading or investment decisions.